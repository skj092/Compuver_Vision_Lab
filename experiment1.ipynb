{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skj092/Computer_Vision_Lab/blob/main/experiment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "# moving kaggle.json to /root/.kaggle\n",
        "mv kaggle.json /root/.kaggle \n",
        "\n",
        "# downloading the dataset\n",
        "kaggle competitions download -c dogs-vs-cats-redux-kernels-edition\n",
        "\n",
        "# unzipping the dataset\n",
        "unzip /content/dogs-vs-cats-redux-kernels-edition.zip \n",
        "\n",
        "# unzipping train and test \n",
        "unzip train.zip \n",
        "\n",
        "unzip test.zip "
      ],
      "metadata": {
        "id": "XmxOICp1zcQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the required libraries\n",
        "import os \n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset, DataLoader, Subset \n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "# creating the dataset class\n",
        "class DogsVsCatsDataset(Dataset):\n",
        "    def __init__(self, images, transform=None):\n",
        "        self.images = images\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.images[idx]\n",
        "        image = Image.open(image_path)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        label = 1 if 'dog' in image_path else 0\n",
        "        return image, label\n",
        "\n",
        "# transform \n",
        "tfms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-10-23T12:10:29.353070Z",
          "iopub.execute_input": "2022-10-23T12:10:29.354004Z",
          "iopub.status.idle": "2022-10-23T12:10:33.998212Z",
          "shell.execute_reply.started": "2022-10-23T12:10:29.353903Z",
          "shell.execute_reply": "2022-10-23T12:10:33.997020Z"
        },
        "trusted": true,
        "id": "YhNKyuNFzIYq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining the training function \n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
        "    train_loss, val_loss, train_acc, val_acc = [], [], [], []\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for xb, yb in tqdm(train_loader):\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            yb_ = model(xb)\n",
        "            loss = criterion(yb_, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss.append(loss.item())\n",
        "            train_acc.append((yb_.argmax(1) == yb).float().mean())\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in tqdm(val_loader):\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                yb_ = model(xb)\n",
        "                loss = criterion(yb_, yb)\n",
        "                val_loss.append(loss.item())\n",
        "                val_acc.append((yb_.argmax(1) == yb).float().mean())\n",
        "        print(f'Epoch: {epoch+1}, Train Loss: {torch.tensor(train_loss).mean():.4f}, Train Accuracy: {torch.tensor(train_acc).mean():.4f}, Val Loss: {torch.tensor(val_loss).mean():.4f}, Val Accuracy: {torch.tensor(val_acc).mean():.4f}')\n",
        "        \n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-10-23T12:10:34.015481Z",
          "iopub.execute_input": "2022-10-23T12:10:34.017530Z",
          "iopub.status.idle": "2022-10-23T12:10:34.037749Z",
          "shell.execute_reply.started": "2022-10-23T12:10:34.016384Z",
          "shell.execute_reply": "2022-10-23T12:10:34.036405Z"
        },
        "trusted": true,
        "id": "0vtiHbMFzIYv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch.nn as nn \n",
        "import torch, torchvision \n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from glob import glob\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "# defining the hyperparameters\n",
        "batch_size = 32\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# path to the dataset\n",
        "path = Path('train')\n",
        "\n",
        "# getting the list of images\n",
        "images = glob(os.path.join(path, '*.jpg'))\n",
        "\n",
        "# splitting the dataset into train and validation\n",
        "train_images, val_images = train_test_split(images, test_size=0.2, random_state=42)\n",
        "\n",
        "# creating the dataset objects\n",
        "train_dataset = DogsVsCatsDataset(train_images, transform=tfms)\n",
        "val_dataset = DogsVsCatsDataset(val_images, transform=tfms)\n",
        "\n",
        "# creating subset of the dataset with 50% of the data\n",
        "train_subset = Subset(train_dataset, indices=range(0, len(train_dataset), 2))\n",
        "valid_subset = Subset(val_dataset, indices=range(0, len(val_dataset), 2))\n",
        "\n",
        "# creating the dataloaders\n",
        "train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(valid_subset, batch_size=32, shuffle=False)\n",
        "\n",
        "# printing the length of the dataset\n",
        "print('Length of the train dataset: ', len(train_dataset))\n",
        "print('Length of the validation dataset: ', len(val_dataset))\n",
        "print('Length of the train subset: ', len(train_subset))\n",
        "print('Length of the validation subset: ', len(valid_subset))\n",
        "\n",
        "# model\n",
        "model = Model()\n",
        "model.to(device)\n",
        "\n",
        "# loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-10-23T12:13:04.271976Z",
          "iopub.execute_input": "2022-10-23T12:13:04.272353Z",
          "iopub.status.idle": "2022-10-23T12:13:10.619109Z",
          "shell.execute_reply.started": "2022-10-23T12:13:04.272318Z",
          "shell.execute_reply": "2022-10-23T12:13:10.618134Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JsA5I0PzIYx",
        "outputId": "62cfd2c1-bd72-496d-8dc8-1c339d6b4959"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of the train dataset:  20000\n",
            "Length of the validation dataset:  5000\n",
            "Length of the train subset:  10000\n",
            "Length of the validation subset:  2500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pretrained alexnet model\n",
        "from torchvision import models \n",
        "\n",
        "# pretrained alexnet model with freezing the weights \n",
        "class AlexNetPretrained(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AlexNetPretrained, self).__init__()\n",
        "        self.model = models.alexnet(pretrained=True)\n",
        "        for param in self.model.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.model.classifier[6] = nn.Linear(4096, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x\n",
        "\n",
        "model = AlexNetPretrained()\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rww_cnJX2hFH",
        "outputId": "bf00e941-062a-43dc-f670-6297bafa01b9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNetPretrained(\n",
              "  (model): AlexNet(\n",
              "    (features): Sequential(\n",
              "      (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "      (4): ReLU(inplace=True)\n",
              "      (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (7): ReLU(inplace=True)\n",
              "      (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (9): ReLU(inplace=True)\n",
              "      (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (11): ReLU(inplace=True)\n",
              "      (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "    (classifier): Sequential(\n",
              "      (0): Dropout(p=0.5, inplace=False)\n",
              "      (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Dropout(p=0.5, inplace=False)\n",
              "      (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): Linear(in_features=4096, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training the model\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-10-23T12:13:10.621166Z",
          "iopub.execute_input": "2022-10-23T12:13:10.621525Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-gBjnsyzIYx",
        "outputId": "ecc55a49-c499-449d-e1b6-9bc3b802256a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:49<00:00,  6.35it/s]\n",
            "100%|██████████| 79/79 [00:12<00:00,  6.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Train Loss: 0.1667, Train Accuracy: 0.9363, Val Loss: 0.1255, Val Accuracy: 0.9513\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:48<00:00,  6.41it/s]\n",
            "100%|██████████| 79/79 [00:12<00:00,  6.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2, Train Loss: 0.1514, Train Accuracy: 0.9433, Val Loss: 0.1369, Val Accuracy: 0.9515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:48<00:00,  6.41it/s]\n",
            "100%|██████████| 79/79 [00:12<00:00,  6.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3, Train Loss: 0.1415, Train Accuracy: 0.9476, Val Loss: 0.1486, Val Accuracy: 0.9500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:49<00:00,  6.38it/s]\n",
            "100%|██████████| 79/79 [00:12<00:00,  6.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4, Train Loss: 0.1350, Train Accuracy: 0.9507, Val Loss: 0.1449, Val Accuracy: 0.9517\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:48<00:00,  6.41it/s]\n",
            "100%|██████████| 79/79 [00:12<00:00,  6.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5, Train Loss: 0.1294, Train Accuracy: 0.9530, Val Loss: 0.1481, Val Accuracy: 0.9522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:48<00:00,  6.40it/s]\n",
            "100%|██████████| 79/79 [00:12<00:00,  6.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 6, Train Loss: 0.1254, Train Accuracy: 0.9550, Val Loss: 0.1527, Val Accuracy: 0.9522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:48<00:00,  6.40it/s]\n",
            "100%|██████████| 79/79 [00:12<00:00,  6.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 7, Train Loss: 0.1228, Train Accuracy: 0.9563, Val Loss: 0.1570, Val Accuracy: 0.9519\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:49<00:00,  6.38it/s]\n",
            "100%|██████████| 79/79 [00:12<00:00,  6.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 8, Train Loss: 0.1207, Train Accuracy: 0.9574, Val Loss: 0.1622, Val Accuracy: 0.9514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:49<00:00,  6.38it/s]\n",
            "100%|██████████| 79/79 [00:12<00:00,  6.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 9, Train Loss: 0.1187, Train Accuracy: 0.9584, Val Loss: 0.1631, Val Accuracy: 0.9516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:49<00:00,  6.38it/s]\n",
            "100%|██████████| 79/79 [00:12<00:00,  6.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10, Train Loss: 0.1175, Train Accuracy: 0.9592, Val Loss: 0.1646, Val Accuracy: 0.9519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GPj9eTgQ6sEc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}